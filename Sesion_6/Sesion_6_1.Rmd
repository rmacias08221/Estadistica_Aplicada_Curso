---
title: "Inferencia Estadística: Diferencias de Medias No Paramétricas"
author: "Ricardo Macías Bohórquez"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    highlight: kate
    code_folding: hide
---

# Inferencia Estadística: Diferencias de Medias No Paramétricas

En este documento, aprenderemos a realizar pruebas de hipótesis no paramétricas para comparar diferencias de medias. Abordaremos las pruebas **Wilcoxon** para muestras pareadas y **U de Mann-Whitney** para dos muestras independientes. Explicaremos paso a paso cómo realizar estas pruebas, sus supuestos, la interpretación de los p-values, y cómo formular las hipótesis.

---

## 1. Conceptos Fundamentales

### 1.1 ¿Por qué utilizar pruebas no paramétricas?

Las pruebas no paramétricas son una alternativa a las pruebas paramétricas cuando no se cumplen los supuestos necesarios, como la normalidad de los datos o la homogeneidad de varianzas. Son útiles para datos ordinales o cuando hay valores atípicos que podrían distorsionar los resultados de una prueba paramétrica.

### 1.2 Hipótesis en Pruebas No Paramétricas

Cada prueba no paramétrica implica dos hipótesis:
- **Hipótesis nula (H0)**: No existe una diferencia significativa entre los grupos.
- **Hipótesis alternativa (H1)**: Existe una diferencia significativa entre los grupos.

---

## 2. Prueba U de Mann-Whitney para dos muestras independientes

### 2.1 Explicación
La prueba **U de Mann-Whitney** (también conocida como Wilcoxon de rango suma) se utiliza para comparar las diferencias entre dos grupos independientes cuando los datos no siguen una distribución normal.

#### **Hipótesis**:
- **H0**: Las distribuciones de las dos muestras son iguales.
- **H1**: Las distribuciones de las dos muestras son diferentes.

### 2.2 Ejemplo: Comparar el `mpg` entre autos con diferentes tipos de transmisión (automática vs manual) en `mtcars`

#### 1. Visualizar los grupos

```{r}
# Cargar la base de datos mtcars
data(mtcars)

# Convertir la variable 'am' a factor
mtcars$am <- factor(mtcars$am, levels = c(0, 1), labels = c("Automática", "Manual"))

# Comparar las medias de 'mpg' entre transmisiones
tapply(mtcars$mpg, mtcars$am, median)
```

#### 2. Realizar la prueba U de Mann-Whitney

```{r}
# Realizar prueba U de Mann-Whitney para dos muestras independientes
wilcox_test_independientes <- wilcox.test(mpg ~ am, data = mtcars)

# Mostrar resultados
print(wilcox_test_independientes)
```

### 2.3 Interpretación del p-value:
- **Si p < 0.05**, rechazamos la hipótesis nula (**H0**) y concluimos que hay una diferencia significativa entre los dos grupos.
- **Si p ≥ 0.05**, no rechazamos la hipótesis nula y concluimos que no hay suficiente evidencia para afirmar que las distribuciones de los grupos son diferentes.

---

## 3. Prueba de Wilcoxon para muestras relacionadas (pareadas)

### 3.1 Explicación
La prueba **Wilcoxon** para muestras relacionadas se utiliza cuando se tienen dos conjuntos de medidas que están emparejadas o relacionadas (por ejemplo, mediciones antes y después de un tratamiento) y no se cumplen los supuestos de normalidad.

#### **Hipótesis**:
- **H0**: Las distribuciones de las dos muestras relacionadas son iguales.
- **H1**: Las distribuciones de las dos muestras relacionadas son diferentes.

### 3.2 Ejemplo: Comparar las mediciones antes y después de un tratamiento hipotético

#### 1. Simular un conjunto de datos

```{r}
# Simular un conjunto de datos
set.seed(123)  # Para reproducibilidad
antes <- rnorm(30, mean = 80, sd = 10)
despues <- antes + rnorm(30, mean = 5, sd = 5)

# Crear un data.frame con los datos
df_pareados <- data.frame(antes, despues)

# Visualizar las primeras filas
head(df_pareados)
```

#### 2. Realizar la prueba de Wilcoxon para muestras relacionadas

```{r}
# Realizar prueba de Wilcoxon para muestras relacionadas
wilcox_test_pareadas <- wilcox.test(df_pareados$antes, df_pareados$despues, paired = TRUE)

# Mostrar resultados
print(wilcox_test_pareadas)
```

### 3.3 Interpretación del p-value:
- **Si p < 0.05**, rechazamos la hipótesis nula y concluimos que hay una diferencia significativa entre las distribuciones de las mediciones antes y después del tratamiento.
- **Si p ≥ 0.05**, no rechazamos la hipótesis nula y concluimos que no hay suficiente evidencia para afirmar que las distribuciones son diferentes.

---

## 4. Ejercicios Prácticos

### **Ejercicio 1**: Prueba U de Mann-Whitney para dos muestras independientes

Compara la variable `hp` (caballos de fuerza) entre autos con diferente número de cilindros (`cyl`). Usa la prueba U de Mann-Whitney para comprobar si hay una diferencia significativa en las distribuciones de caballos de fuerza entre autos con 4 y 6 cilindros.

```{r}
# Convertir cyl a factor
mtcars$cyl <- factor(mtcars$cyl)

# Realizar prueba U de Mann-Whitney
wilcox.test(hp ~ cyl, data = subset(mtcars, cyl %in% c(4, 6)))
```

### **Ejercicio 2**: Prueba de Wilcoxon para muestras pareadas

Simula dos conjuntos de datos relacionados y realiza una prueba de Wilcoxon pareada para comprobar si hay una diferencia significativa entre los dos grupos.

```{r}
# Simular datos pareados
grupo_1 <- rnorm(20, mean = 70, sd = 8)
grupo_2 <- grupo_1 + rnorm(20, mean = 3, sd = 5)

# Realizar la prueba de Wilcoxon pareada
wilcox.test(grupo_1, grupo_2, paired = TRUE)
```
